#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¤šæ¨¡å‹æ—¶é—´åºåˆ—é¢„æµ‹è®­ç»ƒè„šæœ¬
æ”¯æŒä½¿ç”¨ Hugging Face ç»Ÿä¸€æ¥å£çš„é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ—¶é—´åºåˆ—é¢„æµ‹çš„è®­ç»ƒå’Œè¯„ä¼°
"""

import argparse
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import time
import os
import json
from pathlib import Path

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from models.GPT4TS import MultiModelTS
from configs.multimodel_config import (
    get_model_config, print_config_summary, 
    get_preset_model_list, print_available_models
)


class TimeSeriesTrainer:
    """æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹è®­ç»ƒå™¨
    
    æ”¯æŒä»»ä½•åŸºäº Transformer çš„é¢„è®­ç»ƒæ¨¡å‹çš„è®­ç»ƒã€éªŒè¯å’Œè¯„ä¼°æµç¨‹
    """
    
    def __init__(self, config, device):
        """åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            config: æ¨¡å‹é…ç½®å¯¹è±¡
            device: è®¡ç®—è®¾å¤‡
        """
        self.config = config
        self.device = device
        
        # åˆ›å»ºæ¨¡å‹
        self.model = MultiModelTS(config, device)
        
        # è®¾ç½®ä¼˜åŒ–å™¨
        self.optimizer = optim.AdamW(
            self.model.parameters(), 
            lr=config.learning_rate,
            weight_decay=1e-4
        )
        
        # è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, 
            mode='min', 
            factor=0.5, 
            patience=2, 
            verbose=True
        )
        
        # æŸå¤±å‡½æ•°
        self.criterion = nn.MSELoss()
        
        # è®­ç»ƒè®°å½•
        self.train_losses = []
        self.val_losses = []
        self.best_val_loss = float('inf')
        self.patience_counter = 0
        
    def create_synthetic_dataloader(self, split='train'):
        """åˆ›å»ºåˆæˆæ•°æ®çš„æ•°æ®åŠ è½½å™¨
        
        Args:
            split (str): æ•°æ®åˆ†å‰²ç±»å‹ ('train', 'val', 'test')
            
        Returns:
            DataLoader: æ•°æ®åŠ è½½å™¨
        """
        # æ ¹æ®åˆ†å‰²ç±»å‹è®¾ç½®æ•°æ®å¤§å°
        if split == 'train':
            num_samples = 1000
        elif split == 'val':
            num_samples = 200
        else:  # test
            num_samples = 200
        
        # åˆ›å»ºåˆæˆæ—¶é—´åºåˆ—æ•°æ®
        data = []
        for i in range(num_samples):
            # åˆ›å»ºå…·æœ‰ä¸åŒæ¨¡å¼çš„æ—¶é—´åºåˆ—
            t = np.linspace(0, 4*np.pi, self.config.seq_len + self.config.pred_len)
            
            series = []
            for v in range(7):  # 7ä¸ªå˜é‡
                freq = 0.5 + v * 0.1 + np.random.normal(0, 0.05)
                phase = v * np.pi / 4 + np.random.normal(0, 0.1)
                noise = np.random.normal(0, 0.1, len(t))
                
                signal = (np.sin(freq * t + phase) + 
                         0.1 * t + 
                         0.3 * np.sin(2 * freq * t) + 
                         noise)
                series.append(signal)
            
            data.append(np.array(series).T)
        
        data = np.array(data)
        
        # åˆ†å‰²è¾“å…¥å’Œæ ‡ç­¾
        x = data[:, :self.config.seq_len, :]
        y = data[:, self.config.seq_len:, :]
        
        # è½¬æ¢ä¸ºå¼ é‡
        x_tensor = torch.FloatTensor(x)
        y_tensor = torch.FloatTensor(y)
        
        # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
        dataset = TensorDataset(x_tensor, y_tensor)
        dataloader = DataLoader(
            dataset, 
            batch_size=self.config.batch_size, 
            shuffle=(split == 'train'),
            num_workers=2 if split == 'train' else 1
        )
        
        return dataloader
    
    def train_epoch(self, train_loader):
        """è®­ç»ƒä¸€ä¸ªepoch
        
        Args:
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            
        Returns:
            float: å¹³å‡è®­ç»ƒæŸå¤±
        """
        self.model.train()
        total_loss = 0.0
        num_batches = 0
        
        for batch_idx, (x, y) in enumerate(train_loader):
            x, y = x.to(self.device), y.to(self.device)
            
            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            y_pred = self.model(x, itr=batch_idx)
            loss = self.criterion(y_pred, y)
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            self.optimizer.step()
            
            total_loss += loss.item()
            num_batches += 1
            
            # æ‰“å°è¿›åº¦
            if batch_idx % 50 == 0:
                print(f'    Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.6f}')
        
        return total_loss / num_batches
    
    def validate(self, val_loader):
        """éªŒè¯æ¨¡å‹
        
        Args:
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            
        Returns:
            float: å¹³å‡éªŒè¯æŸå¤±
        """
        self.model.eval()
        total_loss = 0.0
        num_batches = 0
        
        with torch.no_grad():
            for x, y in val_loader:
                x, y = x.to(self.device), y.to(self.device)
                y_pred = self.model(x, itr=0)
                loss = self.criterion(y_pred, y)
                
                total_loss += loss.item()
                num_batches += 1
        
        return total_loss / num_batches
    
    def train(self, save_dir='./checkpoints'):
        """å®Œæ•´çš„è®­ç»ƒæµç¨‹
        
        Args:
            save_dir (str): æ¨¡å‹ä¿å­˜ç›®å½•
        """
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹: {self.config.model_name_or_path}")
        print("=" * 60)
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        Path(save_dir).mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        print("ğŸ“Š åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
        train_loader = self.create_synthetic_dataloader('train')
        val_loader = self.create_synthetic_dataloader('val')
        
        print(f"   - è®­ç»ƒæ ·æœ¬: {len(train_loader.dataset)}")
        print(f"   - éªŒè¯æ ·æœ¬: {len(val_loader.dataset)}")
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(self.config.num_epochs):
            epoch_start_time = time.time()
            
            print(f"\nğŸ“ˆ Epoch {epoch+1}/{self.config.num_epochs}")
            print("-" * 40)
            
            # è®­ç»ƒ
            train_loss = self.train_epoch(train_loader)
            self.train_losses.append(train_loss)
            
            # éªŒè¯
            val_loss = self.validate(val_loader)
            self.val_losses.append(val_loss)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            self.scheduler.step(val_loss)
            
            epoch_time = time.time() - epoch_start_time
            
            print(f"   è®­ç»ƒæŸå¤±: {train_loss:.6f}")
            print(f"   éªŒè¯æŸå¤±: {val_loss:.6f}")
            print(f"   å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.2e}")
            print(f"   ç”¨æ—¶: {epoch_time:.2f}s")
            
            # æ—©åœæ£€æŸ¥
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                self.patience_counter = 0
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                self.save_model(save_dir, epoch, is_best=True)
                print(f"   âœ… æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ (éªŒè¯æŸå¤±: {val_loss:.6f})")
                
            else:
                self.patience_counter += 1
                if self.patience_counter >= self.config.patience:
                    print(f"   â¹ï¸  æ—©åœè§¦å‘ (è€å¿ƒå€¼: {self.config.patience})")
                    break
        
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
        print(f"   æœ€ä½³éªŒè¯æŸå¤±: {self.best_val_loss:.6f}")
        
        # ä¿å­˜è®­ç»ƒå†å²
        self.save_training_history(save_dir)
    
    def save_model(self, save_dir, epoch, is_best=False):
        """ä¿å­˜æ¨¡å‹
        
        Args:
            save_dir (str): ä¿å­˜ç›®å½•
            epoch (int): å½“å‰epoch
            is_best (bool): æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
        """
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_val_loss': self.best_val_loss,
            'config': self.config.__dict__
        }
        
        # ä¸ºæ–‡ä»¶ååˆ›å»ºå®‰å…¨çš„æ¨¡å‹åç§°
        safe_model_name = self.config.model_name_or_path.replace('/', '_').replace('\\', '_')
        
        # ä¿å­˜æœ€æ–°æ¨¡å‹
        latest_path = os.path.join(save_dir, f'{safe_model_name}_latest.pth')
        torch.save(checkpoint, latest_path)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if is_best:
            best_path = os.path.join(save_dir, f'{safe_model_name}_best.pth')
            torch.save(checkpoint, best_path)
    
    def save_training_history(self, save_dir):
        """ä¿å­˜è®­ç»ƒå†å²
        
        Args:
            save_dir (str): ä¿å­˜ç›®å½•
        """
        history = {
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'best_val_loss': self.best_val_loss,
            'config': self.config.__dict__
        }
        
        # ä¸ºæ–‡ä»¶ååˆ›å»ºå®‰å…¨çš„æ¨¡å‹åç§°
        safe_model_name = self.config.model_name_or_path.replace('/', '_').replace('\\', '_')
        
        history_path = os.path.join(save_dir, f'{safe_model_name}_history.json')
        with open(history_path, 'w') as f:
            json.dump(history, f, indent=2)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¤šæ¨¡å‹æ—¶é—´åºåˆ—é¢„æµ‹è®­ç»ƒ')
    parser.add_argument('--model', type=str, default='gpt2', 
                      help='è¦è®­ç»ƒçš„æ¨¡å‹ (é¢„è®¾æ¨¡å‹é”®åã€æœ¬åœ°è·¯å¾„æˆ– Hub åç§°)')
    parser.add_argument('--experiment', type=str, default='quick_test',
                      choices=['quick_test', 'small_scale', 'full_scale'],
                      help='å®éªŒè§„æ¨¡')
    parser.add_argument('--device', type=str, default='auto',
                      choices=['auto', 'cpu', 'cuda'],
                      help='è®¡ç®—è®¾å¤‡')
    parser.add_argument('--save_dir', type=str, default='./checkpoints',
                      help='æ¨¡å‹ä¿å­˜ç›®å½•')
    
    args = parser.parse_args()
    
    # è®¾ç½®è®¾å¤‡
    if args.device == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(args.device)
    
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # è·å–æ¨¡å‹é…ç½®
    try:
        config = get_model_config(args.model, args.experiment)
        print(f"\nğŸ“‹ æ¨¡å‹é…ç½®:")
        print_config_summary(config)
    except Exception as e:
        print(f"âŒ é…ç½®é”™è¯¯: {str(e)}")
        return
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(config.seed)
    np.random.seed(config.seed)
    
    # åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
    try:
        trainer = TimeSeriesTrainer(config, device)
        trainer.train(args.save_dir)
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 